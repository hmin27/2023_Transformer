{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "\n",
    "en_vocab_file = \"../data preprocess/en.model\"\n",
    "de_vocab_file = \"../data preprocess/de.model\"\n",
    "\n",
    "en_vocab = spm.SentencePieceProcessor()\n",
    "de_vocab = spm.SentencePieceProcessor()\n",
    "\n",
    "en_vocab.load(en_vocab_file)\n",
    "de_vocab.load(de_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁summer', '▁is', '▁le', 'av', 'ning']\n",
      "['▁winter', '▁is', '▁coming']\n",
      "torch.Size([2, 5])\n",
      "tensor([[3299,   54,  293,  638,  548],\n",
      "        [5026,   54, 1079,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "lines = [\n",
    "  \"summer is leavning\",\n",
    "  \"winter is coming\"\n",
    "]\n",
    "\n",
    "inputs = []\n",
    "for line in lines:\n",
    "  pieces = en_vocab.encode_as_pieces(line)\n",
    "  ids = en_vocab.encode_as_ids(line)\n",
    "  inputs.append(torch.tensor(ids))\n",
    "  print(pieces)\n",
    "\n",
    "# 입력 최대 길이에 맞춰 0으로 패딩\n",
    "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "print(inputs.size())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you so much, Chris.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train_df.csv')\n",
    "train_df['en'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "class en2deDataset(Dataset):\n",
    "    # 생성자 및 데이터 전처리\n",
    "    def __init__(self, dataframe, src_vocab, tgt_vocab):\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    # 데이터셋의 총 길이\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    # idx에 해당하는 입출력 데이터 리턴\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.dataframe['en'][idx]\n",
    "        tgt_sentence = self.dataframe['de'][idx]\n",
    "        \n",
    "        scr_enc = self.src_vocab.encode_as_ids(src_sentence)\n",
    "        tgt_enc = self.tgt_vocab.encode_as_ids(src_sentence)\n",
    "\n",
    "        return torch.tensor(scr_enc), torch.tensor(tgt_enc)\n",
    "# src_vocab 인코딩, tgt_vocab 인코딩을 텐서로 변환하여 튜플 형태로 return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class en2deDataloader():\n",
    "\n",
    "\n",
    "    def collate_fn(batch, pad):\n",
    "        enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True)\n",
    "        dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
